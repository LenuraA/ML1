<h1> Алгоритм 1NN </h1>

<p>Алгоритм ближайшего соседа - 1NN  относит классифицируемый объект $u \in X^{l}$ к тому классу , к которому относится его ближайший сосед.</p>
<p> \begin{align*}
w(i,u) = [i=1]; ~  a(u; X^{l})=y_{u}^{(1)} 
\end{align*} </p>

<h1> Приемущество </h1>
<p> Простота </p>

<h1> Недостатки </h1>
 <p> Неустойчивость к погрешностям — выбросам. 
     Отсутствие параметров, которые можно было бы настраивать по выборке. Алгоритм полностью зависит от того, насколько удачно выбрана
метрика $ρ$.
</p>

<p>
  1. Нужно задать метрическую функцию.
  2. Обучающая выборка сортируется в порядке увеличения расстояния от классифицируемого элемента.
  3. Классифицируемый элемент относим к классу, к которому принадлежит ближайший элемент(первый в отсортированной выборке).
  </p>
  
 
  <p>Метрические алгоритмы классификации с обучающей выборкой $Xl$ относят объект u к тому классу y, для которого суммарный вес ближайших обучающих объектов  $$ W_{y} (u, X^{l})$$ максимален: 
  $$ W_{y} (u, X^{l}) = \sum_{i:yu^{(i)}=y}^{} w(i,u) \to \max$$ </p>
  
  <p> , где весовая функция $w(i, u)$ оценивает степень важности $i$-го соседа для классификации объекта $u$.</p>
  
  <p> Функция $$ W_{y} (u, X^{l})$$  называется оценкой близости объекта $u$ к классу $y$. Выбирая различную весовую функцию $w(i, u)$ можно получать различные метрические классификаторы.</p>
  
  ```R
  distances = function(xl, data, k) { # возвращает отсортированный набор данных по метрике для объекта 
 cases = dim(data)[1]
 features = dim(data)[2]-1
 dists = matrix(0, cases, 2) # создаем матрицу расстояний 
   for (i in 1:cases) {
     cost = k(xl, data[i,1:features])
     dists[i,] = c(cost, i)
   }
   idx = order(dists[,1])
   data[dists[idx,2],]
 }
NN = function(xl, data, k=dist) 
 { # находит 1-ближайшего соседа 
 sorted = distances(xl, data, k)
   sorted[1,features+1]
 }
 ```
